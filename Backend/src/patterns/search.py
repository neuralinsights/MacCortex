# MacCortex SearchPattern - æœç´¢æ¨¡å¼
# Phase 1 - Week 2 Day 9
# åˆ›å»ºæ—¶é—´: 2026-01-20
#
# Web æœç´¢ + è¯­ä¹‰æœç´¢ï¼ˆæœ¬åœ°çŸ¥è¯†åº“æŸ¥è¯¢ï¼‰

import asyncio
from typing import Any, Dict, List
from loguru import logger

from .base import BasePattern
from utils.config import settings


class SearchPattern(BasePattern):
    """
    æœç´¢ Pattern

    æ”¯æŒå¤šç§æœç´¢æ–¹å¼ï¼š
    - Web æœç´¢ï¼ˆGoogleã€DuckDuckGoã€Bingï¼‰
    - è¯­ä¹‰æœç´¢ï¼ˆæœ¬åœ°å‘é‡æ•°æ®åº“ï¼‰
    - æ··åˆæœç´¢ï¼ˆWeb + æœ¬åœ°ï¼‰
    - ç»“æœæ’åºä¸è¿‡æ»¤
    """

    def __init__(self):
        self._mlx_model = None
        self._mlx_tokenizer = None
        self._ollama_client = None
        self._vector_db = None  # ChromaDB å®¢æˆ·ç«¯
        self._mode = "uninitialized"  # uninitialized | mlx | ollama | mock

    # MARK: - BasePattern Protocol

    @property
    def pattern_id(self) -> str:
        return "search"

    @property
    def name(self) -> str:
        return "Search"

    @property
    def description(self) -> str:
        return "Web æœç´¢ + è¯­ä¹‰æœç´¢ï¼ˆæœ¬åœ°çŸ¥è¯†åº“æŸ¥è¯¢ï¼‰"

    @property
    def version(self) -> str:
        return "1.0.0"

    async def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹ä¸æœç´¢å®¢æˆ·ç«¯"""
        logger.info(f"ğŸ”§ åˆå§‹åŒ– {self.name} Pattern...")

        # åˆå§‹åŒ– LLMï¼ˆç”¨äºæŸ¥è¯¢é‡å†™ä¸ç»“æœæ€»ç»“ï¼‰
        try:
            await self._initialize_mlx()
        except Exception as e:
            logger.warning(f"MLX åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ° Ollama: {e}")
            try:
                await self._initialize_ollama()
            except Exception as e2:
                logger.warning(f"Ollama åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ Mock æ¨¡å¼: {e2}")
                logger.info("  âš ï¸  ä½¿ç”¨ Mock æ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰")

        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“ï¼ˆç”¨äºè¯­ä¹‰æœç´¢ï¼‰
        try:
            await self._initialize_vector_db()
        except Exception as e:
            logger.warning(f"å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

    async def _initialize_mlx(self):
        """åˆå§‹åŒ– MLX æ¨¡å‹"""
        try:
            import mlx.core as mx
            from mlx_lm import load

            logger.info(f"  ğŸ åŠ è½½ MLX æ¨¡å‹: {settings.mlx_model}")

            # å¼‚æ­¥åŠ è½½æ¨¡å‹ï¼ˆå¤ç”¨ SummarizePattern çš„æ¨¡å‹ï¼‰
            loop = asyncio.get_event_loop()
            self._mlx_model, self._mlx_tokenizer = await loop.run_in_executor(
                None, load, settings.mlx_model
            )

            self._mode = "mlx"
            logger.info("  âœ… MLX æ¨¡å‹åŠ è½½æˆåŠŸ")
        except ImportError:
            raise RuntimeError("MLX æœªå®‰è£…")
        except Exception as e:
            raise RuntimeError(f"MLX åˆå§‹åŒ–å¤±è´¥: {e}")

    async def _initialize_ollama(self):
        """åˆå§‹åŒ– Ollama å®¢æˆ·ç«¯"""
        try:
            import ollama

            logger.info(f"  ğŸ¦™ è¿æ¥ Ollama: {settings.ollama_model}")

            # æµ‹è¯•è¿æ¥
            client = ollama.AsyncClient()
            try:
                await client.generate(
                    model=settings.ollama_model, prompt="test", options={"num_predict": 1}
                )
                self._ollama_client = client
                self._mode = "ollama"
                logger.info("  âœ… Ollama è¿æ¥æˆåŠŸ")
            except Exception as e:
                raise RuntimeError(f"Ollama è¿æ¥å¤±è´¥: {e}")
        except ImportError:
            raise RuntimeError("Ollama æœªå®‰è£…")

    async def _initialize_vector_db(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“ï¼ˆChromaDBï¼‰"""
        try:
            import chromadb

            logger.info("  ğŸ—„ï¸  è¿æ¥ ChromaDB...")
            self._vector_db = chromadb.Client()
            logger.info("  âœ… ChromaDB è¿æ¥æˆåŠŸ")
        except ImportError:
            logger.warning("ChromaDB æœªå®‰è£…ï¼Œè¯­ä¹‰æœç´¢åŠŸèƒ½ä¸å¯ç”¨")
        except Exception as e:
            logger.warning(f"ChromaDB åˆå§‹åŒ–å¤±è´¥: {e}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self._mlx_model = None
        self._mlx_tokenizer = None
        self._ollama_client = None
        self._vector_db = None
        logger.info(f"âœ… {self.name} Pattern æ¸…ç†å®Œæˆ")

    async def execute(self, text: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œæœç´¢

        Args:
            text: æœç´¢æŸ¥è¯¢
            parameters: æœç´¢å‚æ•°
                - search_type: æœç´¢ç±»å‹ ("web" | "semantic" | "hybrid", é»˜è®¤ "web")
                - engine: æœç´¢å¼•æ“ ("google" | "duckduckgo" | "bing", é»˜è®¤ "duckduckgo")
                - num_results: è¿”å›ç»“æœæ•°é‡ (é»˜è®¤: 5)
                - summarize: æ˜¯å¦æ€»ç»“æœç´¢ç»“æœ (é»˜è®¤: true)
                - language: æœç´¢è¯­è¨€ (é»˜è®¤: "zh-CN")
                - collection: è¯­ä¹‰æœç´¢çš„é›†åˆåç§° (é»˜è®¤: "default")

        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        # è§£æå‚æ•°
        search_type = parameters.get("search_type", "web")
        engine = parameters.get("engine", "duckduckgo")
        num_results = parameters.get("num_results", 5)
        summarize = parameters.get("summarize", True)
        language = parameters.get("language", "zh-CN")
        collection = parameters.get("collection", "default")

        # æ‰§è¡Œæœç´¢
        if search_type == "web":
            results = await self._web_search(text, engine, num_results, language)
        elif search_type == "semantic":
            results = await self._semantic_search(text, collection, num_results)
        elif search_type == "hybrid":
            web_results = await self._web_search(text, engine, num_results // 2, language)
            semantic_results = await self._semantic_search(text, collection, num_results // 2)
            results = web_results + semantic_results
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æœç´¢ç±»å‹: {search_type}")

        # æ€»ç»“æœç´¢ç»“æœï¼ˆå¦‚æœéœ€è¦ï¼‰
        summary = None
        if summarize and results:
            summary = await self._summarize_results(text, results)

        # åºåˆ—åŒ–æœç´¢ç»“æœä¸º JSON å­—ç¬¦ä¸²ï¼ˆç»Ÿä¸€è¾“å‡ºæ ¼å¼ï¼‰
        search_result = {
            "results": results[:num_results],
            "summary": summary,
        }

        import json
        output = json.dumps(search_result, ensure_ascii=False, indent=2)

        return {
            "output": output,  # ç»Ÿä¸€è¾“å‡ºæ ¼å¼
            "metadata": {
                "search_type": search_type,
                "engine": engine,
                "num_results": num_results,
                "query": text,
                "total_found": len(results),
                "mode": self._mode,
            },
        }

    async def _web_search(self, query: str, engine: str, num_results: int, language: str) -> List[Dict[str, Any]]:
        """Web æœç´¢"""
        if engine == "duckduckgo":
            return await self._search_duckduckgo(query, num_results, language)
        elif engine == "google":
            return await self._search_google(query, num_results, language)
        elif engine == "bing":
            return await self._search_bing(query, num_results, language)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æœç´¢å¼•æ“: {engine}")

    async def _search_duckduckgo(self, query: str, num_results: int, language: str) -> List[Dict[str, Any]]:
        """DuckDuckGo æœç´¢"""
        try:
            from duckduckgo_search import DDGS

            results = []
            with DDGS() as ddgs:
                for i, result in enumerate(ddgs.text(query, region="cn-zh" if language == "zh-CN" else "us-en", max_results=num_results)):
                    results.append(
                        {
                            "title": result.get("title", ""),
                            "url": result.get("href", ""),
                            "snippet": result.get("body", ""),
                            "source": "duckduckgo",
                            "rank": i + 1,
                        }
                    )
            return results
        except ImportError:
            logger.warning("duckduckgo_search æœªå®‰è£…ï¼Œä½¿ç”¨ Mock æœç´¢")
            return await self._mock_web_search(query, num_results)
        except Exception as e:
            logger.error(f"DuckDuckGo æœç´¢å¤±è´¥: {e}")
            return await self._mock_web_search(query, num_results)

    async def _search_google(self, query: str, num_results: int, language: str) -> List[Dict[str, Any]]:
        """Google æœç´¢ï¼ˆéœ€è¦ API Keyï¼‰"""
        # TODO: å®ç° Google Custom Search API
        logger.warning("Google æœç´¢æš‚æœªå®ç°ï¼Œä½¿ç”¨ Mock æœç´¢")
        return await self._mock_web_search(query, num_results)

    async def _search_bing(self, query: str, num_results: int, language: str) -> List[Dict[str, Any]]:
        """Bing æœç´¢ï¼ˆéœ€è¦ API Keyï¼‰"""
        # TODO: å®ç° Bing Search API
        logger.warning("Bing æœç´¢æš‚æœªå®ç°ï¼Œä½¿ç”¨ Mock æœç´¢")
        return await self._mock_web_search(query, num_results)

    async def _mock_web_search(self, query: str, num_results: int) -> List[Dict[str, Any]]:
        """Mock Web æœç´¢ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        await asyncio.sleep(0.1)

        return [
            {
                "title": f"MacCortex æœç´¢ç»“æœ {i + 1}",
                "url": f"https://example.com/result{i + 1}",
                "snippet": f"è¿™æ˜¯å…³äº '{query}' çš„æœç´¢ç»“æœ {i + 1}ã€‚MacCortex æ˜¯ä¸‹ä¸€ä»£ macOS ä¸ªäººæ™ºèƒ½åŸºç¡€è®¾æ–½ã€‚",
                "source": "mock",
                "rank": i + 1,
            }
            for i in range(num_results)
        ]

    async def _semantic_search(self, query: str, collection: str, num_results: int) -> List[Dict[str, Any]]:
        """è¯­ä¹‰æœç´¢ï¼ˆå‘é‡æ•°æ®åº“ï¼‰"""
        if not self._vector_db:
            logger.warning("ChromaDB æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ Mock è¯­ä¹‰æœç´¢")
            return await self._mock_semantic_search(query, num_results)

        try:
            # è·å–é›†åˆ
            col = self._vector_db.get_or_create_collection(name=collection)

            # æŸ¥è¯¢
            results = col.query(query_texts=[query], n_results=num_results)

            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            if results["documents"] and results["documents"][0]:
                for i, (doc, metadata, distance) in enumerate(
                    zip(results["documents"][0], results["metadatas"][0], results["distances"][0])
                ):
                    formatted_results.append(
                        {
                            "title": metadata.get("title", f"æ–‡æ¡£ {i + 1}"),
                            "content": doc,
                            "metadata": metadata,
                            "similarity": 1.0 - distance,  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                            "source": "chromadb",
                            "rank": i + 1,
                        }
                    )

            return formatted_results
        except Exception as e:
            logger.error(f"è¯­ä¹‰æœç´¢å¤±è´¥: {e}")
            return await self._mock_semantic_search(query, num_results)

    async def _mock_semantic_search(self, query: str, num_results: int) -> List[Dict[str, Any]]:
        """Mock è¯­ä¹‰æœç´¢ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        await asyncio.sleep(0.1)

        return [
            {
                "title": f"æœ¬åœ°æ–‡æ¡£ {i + 1}",
                "content": f"è¿™æ˜¯å…³äº '{query}' çš„æœ¬åœ°æ–‡æ¡£ {i + 1}ã€‚åŒ…å«ç›¸å…³ä¿¡æ¯å’Œä¸Šä¸‹æ–‡ã€‚",
                "metadata": {"source": "mock", "created_at": "2026-01-20"},
                "similarity": 0.9 - (i * 0.1),
                "source": "mock_vector_db",
                "rank": i + 1,
            }
            for i in range(num_results)
        ]

    async def _summarize_results(self, query: str, results: List[Dict[str, Any]]) -> str:
        """æ€»ç»“æœç´¢ç»“æœ"""
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³ç»“æœã€‚"

        # æ„å»ºæ€»ç»“æç¤ºè¯
        results_text = "\n\n".join(
            [f"ç»“æœ {i + 1}: {r.get('title', '')}\n{r.get('snippet', '') or r.get('content', '')}" for i, r in enumerate(results[:5])]
        )

        prompt = f"""æ ¹æ®ä»¥ä¸‹æœç´¢ç»“æœï¼Œç®€è¦å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{query}

æœç´¢ç»“æœï¼š
{results_text}

è¯·ç”¨ 2-3 å¥è¯æ€»ç»“æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚"""

        # ä½¿ç”¨ LLM ç”Ÿæˆæ€»ç»“
        if self._mode == "mlx":
            from mlx_lm import generate

            loop = asyncio.get_event_loop()
            summary = await loop.run_in_executor(
                None,
                generate,
                self._mlx_model,
                self._mlx_tokenizer,
                prompt,
                256,  # max_tokens
            )
            return summary.strip()
        elif self._mode == "ollama":
            response = await self._ollama_client.generate(
                model=settings.ollama_model, prompt=prompt, options={"temperature": 0.7, "num_predict": 256}
            )
            return response["response"].strip()
        else:
            # Mock æ€»ç»“
            return f"æ ¹æ®æœç´¢ç»“æœï¼Œå…³äº '{query}' çš„ä¸»è¦ä¿¡æ¯å¦‚ä¸‹ï¼š{results[0].get('title', '')}ã€‚è¯¦è§æœç´¢ç»“æœã€‚"
