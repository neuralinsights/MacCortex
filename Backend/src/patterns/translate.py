# MacCortex TranslatePattern - ç¿»è¯‘æ¨¡å¼
# Phase 1 - Week 2 Day 9
# åˆ›å»ºæ—¶é—´: 2026-01-20
#
# å¤šè¯­è¨€ç¿»è¯‘ï¼ˆæ”¯æŒä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰ï¼‰

import asyncio
from typing import Any, Dict
from loguru import logger

from .base import BasePattern
from utils.config import settings


class TranslatePattern(BasePattern):
    """
    ç¿»è¯‘ Pattern

    æ”¯æŒå¤šç§è¯­è¨€ä¹‹é—´çš„ç¿»è¯‘ï¼š
    - ä¸­æ–‡ â†” è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ã€æ³•æ–‡ã€å¾·æ–‡ã€è¥¿ç­ç‰™æ–‡ç­‰
    - è‡ªåŠ¨æ£€æµ‹æºè¯­è¨€
    - ä¿ç•™æ ¼å¼ä¸æœ¯è¯­
    - æ”¯æŒä¸“ä¸šæœ¯è¯­è¯å…¸
    """

    def __init__(self):
        self._mlx_model = None
        self._mlx_tokenizer = None
        self._ollama_client = None
        self._mode = "uninitialized"  # uninitialized | mlx | ollama | mock

    # MARK: - BasePattern Protocol

    @property
    def pattern_id(self) -> str:
        return "translate"

    @property
    def name(self) -> str:
        return "Translate"

    @property
    def description(self) -> str:
        return "å¤šè¯­è¨€ç¿»è¯‘ï¼ˆæ”¯æŒä¸­è‹±æ—¥éŸ©æ³•å¾·è¥¿ç­‰ï¼‰"

    @property
    def version(self) -> str:
        return "1.0.0"

    async def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        logger.info(f"ğŸ”§ åˆå§‹åŒ– {self.name} Pattern...")

        # å°è¯•åŠ è½½ MLX æ¨¡å‹ï¼ˆApple Silicon ä¼˜åŒ–ï¼‰
        try:
            await self._initialize_mlx()
        except Exception as e:
            logger.warning(f"MLX åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ° Ollama: {e}")
            try:
                await self._initialize_ollama()
            except Exception as e2:
                logger.warning(f"Ollama åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ Mock æ¨¡å¼: {e2}")
                logger.info("  âš ï¸  ä½¿ç”¨ Mock æ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰")

    async def _initialize_mlx(self):
        """åˆå§‹åŒ– MLX æ¨¡å‹"""
        try:
            import mlx.core as mx
            from mlx_lm import load

            logger.info(f"  ğŸ åŠ è½½ MLX æ¨¡å‹: {settings.mlx_model}")

            # å¼‚æ­¥åŠ è½½æ¨¡å‹ï¼ˆå¤ç”¨ SummarizePattern çš„æ¨¡å‹ï¼‰
            loop = asyncio.get_event_loop()
            self._mlx_model, self._mlx_tokenizer = await loop.run_in_executor(
                None, load, settings.mlx_model
            )

            self._mode = "mlx"
            logger.info("  âœ… MLX æ¨¡å‹åŠ è½½æˆåŠŸ")
        except ImportError:
            raise RuntimeError("MLX æœªå®‰è£…")
        except Exception as e:
            raise RuntimeError(f"MLX åˆå§‹åŒ–å¤±è´¥: {e}")

    async def _initialize_ollama(self):
        """åˆå§‹åŒ– Ollama å®¢æˆ·ç«¯"""
        try:
            import ollama

            logger.info(f"  ğŸ¦™ è¿æ¥ Ollama: {settings.ollama_model}")

            # æµ‹è¯•è¿æ¥
            client = ollama.AsyncClient()
            try:
                await client.generate(
                    model=settings.ollama_model, prompt="test", options={"num_predict": 1}
                )
                self._ollama_client = client
                self._mode = "ollama"
                logger.info("  âœ… Ollama è¿æ¥æˆåŠŸ")
            except Exception as e:
                raise RuntimeError(f"Ollama è¿æ¥å¤±è´¥: {e}")
        except ImportError:
            raise RuntimeError("Ollama æœªå®‰è£…")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self._mlx_model = None
        self._mlx_tokenizer = None
        self._ollama_client = None
        logger.info(f"âœ… {self.name} Pattern æ¸…ç†å®Œæˆ")

    async def execute(self, text: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œç¿»è¯‘

        Args:
            text: è¾“å…¥æ–‡æœ¬
            parameters: ç¿»è¯‘å‚æ•°
                - target_language: ç›®æ ‡è¯­è¨€ (å¿…å¡«, å¦‚ "en", "ja", "ko", "fr", "de", "es")
                - source_language: æºè¯­è¨€ (å¯é€‰, é»˜è®¤ "auto" è‡ªåŠ¨æ£€æµ‹)
                - style: ç¿»è¯‘é£æ ¼ (å¯é€‰, "formal"|"casual"|"technical", é»˜è®¤ "formal")
                - preserve_format: æ˜¯å¦ä¿ç•™æ ¼å¼ (é»˜è®¤: true)
                - glossary: æœ¯è¯­è¯å…¸ (å¯é€‰, Dict[str, str])

        Returns:
            ç¿»è¯‘ç»“æœå­—å…¸
        """
        # è§£æå‚æ•°
        target_language = parameters.get("target_language")
        if not target_language:
            raise ValueError("ç¼ºå°‘å¿…å¡«å‚æ•°: target_language")

        source_language = parameters.get("source_language", "auto")
        style = parameters.get("style", "formal")
        preserve_format = parameters.get("preserve_format", True)
        glossary = parameters.get("glossary", {})

        # æ ¹æ®æ¨¡å¼é€‰æ‹©ç”Ÿæˆæ–¹æ³•
        if self._mode == "mlx":
            translation = await self._translate_with_mlx(
                text, source_language, target_language, style, preserve_format, glossary
            )
        elif self._mode == "ollama":
            translation = await self._translate_with_ollama(
                text, source_language, target_language, style, preserve_format, glossary
            )
        else:
            # Mock æ¨¡å¼
            translation = await self._translate_mock(
                text, source_language, target_language, style, preserve_format, glossary
            )

        return {
            "output": translation,  # ç»Ÿä¸€è¾“å‡ºæ ¼å¼
            "metadata": {
                "source_language": source_language,
                "target_language": target_language,
                "style": style,
                "preserve_format": preserve_format,
                "glossary_size": len(glossary),
                "original_length": len(text),
                "translation_length": len(translation),
                "mode": self._mode,
            },
        }

    async def _translate_with_mlx(
        self,
        text: str,
        source_language: str,
        target_language: str,
        style: str,
        preserve_format: bool,
        glossary: Dict[str, str],
    ) -> str:
        """ä½¿ç”¨ MLX æ¨¡å‹è¿›è¡Œç¿»è¯‘"""
        from mlx_lm import generate

        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(text, source_language, target_language, style, preserve_format, glossary)

        # ç”Ÿæˆï¼ˆåŒæ­¥æ–¹æ³•ï¼Œéœ€è¦åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰
        loop = asyncio.get_event_loop()
        output = await loop.run_in_executor(
            None,
            generate,
            self._mlx_model,
            self._mlx_tokenizer,
            prompt,
            1024,  # max_tokens
        )

        # æå–ç¿»è¯‘ç»“æœ
        return self._extract_translation(output)

    async def _translate_with_ollama(
        self,
        text: str,
        source_language: str,
        target_language: str,
        style: str,
        preserve_format: bool,
        glossary: Dict[str, str],
    ) -> str:
        """ä½¿ç”¨ Ollama è¿›è¡Œç¿»è¯‘"""
        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(text, source_language, target_language, style, preserve_format, glossary)

        # ç”Ÿæˆ
        response = await self._ollama_client.generate(
            model=settings.ollama_model, prompt=prompt, options={"temperature": 0.5, "num_predict": 1024}
        )

        # æå–ç¿»è¯‘ç»“æœ
        return self._extract_translation(response["response"])

    async def _translate_mock(
        self,
        text: str,
        source_language: str,
        target_language: str,
        style: str,
        preserve_format: bool,
        glossary: Dict[str, str],
    ) -> str:
        """Mock æ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        await asyncio.sleep(0.1)

        # ç®€å•çš„ Mock ç¿»è¯‘
        mock_translations = {
            "zh-CN_en": "This is a mock translation from Chinese to English.",
            "en_zh-CN": "è¿™æ˜¯ä»è‹±æ–‡åˆ°ä¸­æ–‡çš„æ¨¡æ‹Ÿç¿»è¯‘ã€‚",
            "zh-CN_ja": "ã“ã‚Œã¯ä¸­å›½èªã‹ã‚‰æ—¥æœ¬èªã¸ã®ãƒ¢ãƒƒã‚¯ç¿»è¨³ã§ã™ã€‚",
            "zh-CN_ko": "ì´ê²ƒì€ ì¤‘êµ­ì–´ì—ì„œ í•œêµ­ì–´ë¡œì˜ ëª¨ì˜ ë²ˆì—­ì…ë‹ˆë‹¤.",
            "zh-CN_fr": "Ceci est une traduction simulÃ©e du chinois vers le franÃ§ais.",
            "zh-CN_de": "Dies ist eine Mock-Ãœbersetzung vom Chinesischen ins Deutsche.",
            "zh-CN_es": "Esta es una traducciÃ³n simulada del chino al espaÃ±ol.",
        }

        # è‡ªåŠ¨æ£€æµ‹æºè¯­è¨€ï¼ˆç®€å•åˆ¤æ–­ï¼‰
        if source_language == "auto":
            # æ£€æµ‹æ˜¯å¦æœ‰ä¸­æ–‡å­—ç¬¦
            has_chinese = any("\u4e00" <= c <= "\u9fff" for c in text)
            source_language = "zh-CN" if has_chinese else "en"

        key = f"{source_language}_{target_language}"
        translation = mock_translations.get(key, f"[Mock ç¿»è¯‘] åŸæ–‡é•¿åº¦: {len(text)} å­—ç¬¦")

        # æ·»åŠ é£æ ¼æ ‡è®°
        if style == "formal":
            translation = f"[æ­£å¼é£æ ¼] {translation}"
        elif style == "casual":
            translation = f"[éšæ„é£æ ¼] {translation}"
        elif style == "technical":
            translation = f"[æŠ€æœ¯é£æ ¼] {translation}"

        return translation

    def _build_prompt(
        self,
        text: str,
        source_language: str,
        target_language: str,
        style: str,
        preserve_format: bool,
        glossary: Dict[str, str],
    ) -> str:
        """æ„å»ºç¿»è¯‘æç¤ºè¯"""
        # è¯­è¨€ä»£ç æ˜ å°„
        lang_names = {
            "auto": "è‡ªåŠ¨æ£€æµ‹",
            "zh-CN": "ç®€ä½“ä¸­æ–‡",
            "zh-TW": "ç¹ä½“ä¸­æ–‡",
            "en": "English",
            "ja": "æ—¥æœ¬èª",
            "ko": "í•œêµ­ì–´",
            "fr": "FranÃ§ais",
            "de": "Deutsch",
            "es": "EspaÃ±ol",
            "ru": "Ğ ÑƒÑÑĞºĞ¸Ğ¹",
            "ar": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        }

        source_name = lang_names.get(source_language, source_language)
        target_name = lang_names.get(target_language, target_language)

        # é£æ ¼æè¿°
        style_desc = {"formal": "æ­£å¼ã€ä¸“ä¸š", "casual": "éšæ„ã€å£è¯­åŒ–", "technical": "æŠ€æœ¯ã€ç²¾ç¡®"}.get(style, "æ­£å¼")

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘ä¸º {target_name}ã€‚

åŸæ–‡ï¼ˆ{source_name}ï¼‰ï¼š
{text}

ç¿»è¯‘è¦æ±‚ï¼š
- ç›®æ ‡è¯­è¨€ï¼š{target_name}
- ç¿»è¯‘é£æ ¼ï¼š{style_desc}
"""

        if preserve_format:
            prompt += "- ä¿ç•™åŸæ–‡æ ¼å¼ï¼ˆæ¢è¡Œã€æ®µè½ã€æ ‡ç‚¹ç­‰ï¼‰\n"

        if glossary:
            prompt += f"- æœ¯è¯­è¯å…¸ï¼š{glossary}\n"

        prompt += "\nè¯·ç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚"

        return prompt

    def _extract_translation(self, output: str) -> str:
        """ä»æ¨¡å‹è¾“å‡ºä¸­æå–ç¿»è¯‘ç»“æœ"""
        # å»é™¤å¯èƒ½çš„å‰ç¼€/åç¼€è¯´æ˜
        output = output.strip()

        # ç§»é™¤å¸¸è§çš„å‰ç¼€æ¨¡å¼
        prefixes = ["ç¿»è¯‘ç»“æœï¼š", "Translation:", "è¯‘æ–‡ï¼š", "Result:"]
        for prefix in prefixes:
            if output.startswith(prefix):
                output = output[len(prefix) :].strip()

        # ç§»é™¤ä»£ç å—æ ‡è®°ï¼ˆå¦‚æœæœ‰ï¼‰
        if output.startswith("```") and output.endswith("```"):
            lines = output.split("\n")
            output = "\n".join(lines[1:-1])

        return output.strip()
