#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright (c) 2026 Yu Geng. All rights reserved.
# MacCortex - Proprietary and Confidential

# MacCortex TranslatePattern - ç¿»è¯‘æ¨¡å¼
# Phase 1 - Week 2 Day 9
# åˆ›å»ºæ—¶é—´: 2026-01-20
# æ›´æ–°æ—¶é—´: 2026-01-21 (Phase 1.5 - Day 3: é›†æˆ PromptGuard)
#
# Phase 1.5: å¢å¼ºå®‰å…¨é˜²æŠ¤ï¼ˆPrompt Injection æ£€æµ‹ã€æŒ‡ä»¤éš”ç¦»ã€è¾“å‡ºæ¸…ç†ï¼‰
#
# å¤šè¯­è¨€ç¿»è¯‘ï¼ˆæ”¯æŒä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰ï¼‰

import asyncio
from typing import Any, Dict
from loguru import logger

from .base import BasePattern
from utils.config import settings


class TranslatePattern(BasePattern):
    """
    ç¿»è¯‘ Pattern

    æ”¯æŒå¤šç§è¯­è¨€ä¹‹é—´çš„ç¿»è¯‘ï¼š
    - ä¸­æ–‡ â†” è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ã€æ³•æ–‡ã€å¾·æ–‡ã€è¥¿ç­ç‰™æ–‡ç­‰
    - è‡ªåŠ¨æ£€æµ‹æºè¯­è¨€
    - ä¿ç•™æ ¼å¼ä¸æœ¯è¯­
    - æ”¯æŒä¸“ä¸šæœ¯è¯­è¯å…¸
    """

    def __init__(self):
        super().__init__()  # Phase 1.5: åˆå§‹åŒ–å®‰å…¨æ¨¡å—
        self._mlx_model = None
        self._mlx_tokenizer = None
        self._ollama_client = None
        self._mode = "uninitialized"  # uninitialized | mlx | ollama | mock

    # MARK: - BasePattern Protocol

    @property
    def pattern_id(self) -> str:
        return "translate"

    @property
    def name(self) -> str:
        return "Translate"

    @property
    def description(self) -> str:
        return "å¤šè¯­è¨€ç¿»è¯‘ï¼ˆæ”¯æŒä¸­è‹±æ—¥éŸ©æ³•å¾·è¥¿ç­‰ï¼‰"

    @property
    def version(self) -> str:
        return "1.0.0"

    async def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        logger.info(f"ğŸ”§ åˆå§‹åŒ– {self.name} Pattern...")

        # å°è¯•åŠ è½½ MLX æ¨¡å‹ï¼ˆApple Silicon ä¼˜åŒ–ï¼‰
        try:
            await self._initialize_mlx()
        except Exception as e:
            logger.warning(f"MLX åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ° Ollama: {e}")
            try:
                await self._initialize_ollama()
            except Exception as e2:
                logger.warning(f"Ollama åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ Mock æ¨¡å¼: {e2}")
                logger.info("  âš ï¸  ä½¿ç”¨ Mock æ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰")

    async def _initialize_mlx(self):
        """åˆå§‹åŒ– MLX æ¨¡å‹"""
        try:
            import mlx.core as mx
            from mlx_lm import load

            logger.info(f"  ğŸ åŠ è½½ MLX æ¨¡å‹: {settings.mlx_model}")

            # å¼‚æ­¥åŠ è½½æ¨¡å‹ï¼ˆå¤ç”¨ SummarizePattern çš„æ¨¡å‹ï¼‰
            loop = asyncio.get_event_loop()
            self._mlx_model, self._mlx_tokenizer = await loop.run_in_executor(
                None, load, settings.mlx_model
            )

            self._mode = "mlx"
            logger.info("  âœ… MLX æ¨¡å‹åŠ è½½æˆåŠŸ")
        except ImportError:
            raise RuntimeError("MLX æœªå®‰è£…")
        except Exception as e:
            raise RuntimeError(f"MLX åˆå§‹åŒ–å¤±è´¥: {e}")

    async def _initialize_ollama(self):
        """åˆå§‹åŒ– Ollama å®¢æˆ·ç«¯"""
        try:
            import ollama

            logger.info(f"  ğŸ¦™ è¿æ¥ Ollama: {settings.ollama_model}")

            # æµ‹è¯•è¿æ¥
            client = ollama.AsyncClient()
            try:
                await client.generate(
                    model=settings.ollama_model, prompt="test", options={"num_predict": 1}
                )
                self._ollama_client = client
                self._mode = "ollama"
                logger.info("  âœ… Ollama è¿æ¥æˆåŠŸ")
            except Exception as e:
                raise RuntimeError(f"Ollama è¿æ¥å¤±è´¥: {e}")
        except ImportError:
            raise RuntimeError("Ollama æœªå®‰è£…")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self._mlx_model = None
        self._mlx_tokenizer = None
        self._ollama_client = None
        logger.info(f"âœ… {self.name} Pattern æ¸…ç†å®Œæˆ")

    async def execute(self, text: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œç¿»è¯‘

        Args:
            text: è¾“å…¥æ–‡æœ¬
            parameters: ç¿»è¯‘å‚æ•°
                - target_language: ç›®æ ‡è¯­è¨€ (å¿…å¡«, å¦‚ "en", "ja", "ko", "fr", "de", "es")
                - source_language: æºè¯­è¨€ (å¯é€‰, é»˜è®¤ "auto" è‡ªåŠ¨æ£€æµ‹)
                - style: ç¿»è¯‘é£æ ¼ (å¯é€‰, "formal"|"casual"|"technical", é»˜è®¤ "formal")
                - preserve_format: æ˜¯å¦ä¿ç•™æ ¼å¼ (é»˜è®¤: true)
                - glossary: æœ¯è¯­è¯å…¸ (å¯é€‰, Dict[str, str])

        Returns:
            ç¿»è¯‘ç»“æœå­—å…¸
        """
        # è§£æå‚æ•°
        target_language = parameters.get("target_language")
        if not target_language:
            raise ValueError("ç¼ºå°‘å¿…å¡«å‚æ•°: target_language")

        source_language = parameters.get("source_language", "auto")
        style = parameters.get("style", "formal")
        preserve_format = parameters.get("preserve_format", True)
        glossary = parameters.get("glossary", {})

        # æ ¹æ®æ¨¡å¼é€‰æ‹©ç”Ÿæˆæ–¹æ³•
        if self._mode == "mlx":
            translation = await self._translate_with_mlx(
                text, source_language, target_language, style, preserve_format, glossary
            )
        elif self._mode == "ollama":
            translation = await self._translate_with_ollama(
                text, source_language, target_language, style, preserve_format, glossary
            )
        else:
            # Mock æ¨¡å¼
            translation = await self._translate_mock(
                text, source_language, target_language, style, preserve_format, glossary
            )

        return {
            "output": translation,  # ç»Ÿä¸€è¾“å‡ºæ ¼å¼
            "metadata": {
                "source_language": source_language,
                "target_language": target_language,
                "style": style,
                "preserve_format": preserve_format,
                "glossary_size": len(glossary),
                "original_length": len(text),
                "translation_length": len(translation),
                "mode": self._mode,
            },
        }

    async def _translate_with_mlx(
        self,
        text: str,
        source_language: str,
        target_language: str,
        style: str,
        preserve_format: bool,
        glossary: Dict[str, str],
    ) -> str:
        """ä½¿ç”¨ MLX æ¨¡å‹è¿›è¡Œç¿»è¯‘"""
        from mlx_lm import generate

        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(text, source_language, target_language, style, preserve_format, glossary)

        # ç”Ÿæˆï¼ˆåŒæ­¥æ–¹æ³•ï¼Œéœ€è¦åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼‰
        loop = asyncio.get_event_loop()
        output = await loop.run_in_executor(
            None,
            generate,
            self._mlx_model,
            self._mlx_tokenizer,
            prompt,
            1024,  # max_tokens
        )

        # æå–ç¿»è¯‘ç»“æœ
        return self._extract_translation(output)

    async def _translate_with_ollama(
        self,
        text: str,
        source_language: str,
        target_language: str,
        style: str,
        preserve_format: bool,
        glossary: Dict[str, str],
    ) -> str:
        """ä½¿ç”¨ Ollama è¿›è¡Œç¿»è¯‘"""
        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(text, source_language, target_language, style, preserve_format, glossary)

        # ç”Ÿæˆ
        response = await self._ollama_client.generate(
            model=settings.ollama_model, prompt=prompt, options={"temperature": 0.5, "num_predict": 1024}
        )

        # æå–ç¿»è¯‘ç»“æœ
        return self._extract_translation(response["response"])

    async def _translate_mock(
        self,
        text: str,
        source_language: str,
        target_language: str,
        style: str,
        preserve_format: bool,
        glossary: Dict[str, str],
    ) -> str:
        """Mock æ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        await asyncio.sleep(0.1)

        # ç®€å•çš„ Mock ç¿»è¯‘
        mock_translations = {
            "zh-CN_en": "This is a mock translation from Chinese to English.",
            "en_zh-CN": "è¿™æ˜¯ä»è‹±æ–‡åˆ°ä¸­æ–‡çš„æ¨¡æ‹Ÿç¿»è¯‘ã€‚",
            "zh-CN_ja": "ã“ã‚Œã¯ä¸­å›½èªã‹ã‚‰æ—¥æœ¬èªã¸ã®ãƒ¢ãƒƒã‚¯ç¿»è¨³ã§ã™ã€‚",
            "zh-CN_ko": "ì´ê²ƒì€ ì¤‘êµ­ì–´ì—ì„œ í•œêµ­ì–´ë¡œì˜ ëª¨ì˜ ë²ˆì—­ì…ë‹ˆë‹¤.",
            "zh-CN_fr": "Ceci est une traduction simulÃ©e du chinois vers le franÃ§ais.",
            "zh-CN_de": "Dies ist eine Mock-Ãœbersetzung vom Chinesischen ins Deutsche.",
            "zh-CN_es": "Esta es una traducciÃ³n simulada del chino al espaÃ±ol.",
        }

        # è‡ªåŠ¨æ£€æµ‹æºè¯­è¨€ï¼ˆç®€å•åˆ¤æ–­ï¼‰
        if source_language == "auto":
            # æ£€æµ‹æ˜¯å¦æœ‰ä¸­æ–‡å­—ç¬¦
            has_chinese = any("\u4e00" <= c <= "\u9fff" for c in text)
            source_language = "zh-CN" if has_chinese else "en"

        key = f"{source_language}_{target_language}"
        translation = mock_translations.get(key, f"[Mock ç¿»è¯‘] åŸæ–‡é•¿åº¦: {len(text)} å­—ç¬¦")

        # æ·»åŠ é£æ ¼æ ‡è®°
        if style == "formal":
            translation = f"[æ­£å¼é£æ ¼] {translation}"
        elif style == "casual":
            translation = f"[éšæ„é£æ ¼] {translation}"
        elif style == "technical":
            translation = f"[æŠ€æœ¯é£æ ¼] {translation}"

        return translation

    def _build_prompt(
        self,
        text: str,
        source_language: str,
        target_language: str,
        style: str,
        preserve_format: bool,
        glossary: Dict[str, str],
    ) -> str:
        """
        æ„å»ºç¿»è¯‘æç¤ºè¯ï¼ˆPhase 2 Week 4 Day 16 ä¼˜åŒ–ï¼‰

        ä¼˜åŒ–è¦ç‚¹ï¼š
        1. ç®€åŒ–ç³»ç»Ÿæç¤ºï¼Œæ˜ç¡®ä»»åŠ¡ç›®æ ‡
        2. å¼ºè°ƒ"åªè¾“å‡ºç¿»è¯‘"ï¼Œé¿å…é‡å¤åŸæ–‡
        3. ä½¿ç”¨ IMPORTANT æ ‡è®°å…³é”®è§„åˆ™
        """
        # è¯­è¨€ä»£ç æ˜ å°„ï¼ˆPhase 2 Week 4 Day 16ï¼šåŒæ—¶æ”¯æŒç®€çŸ­å’Œå®Œæ•´æ ¼å¼ï¼‰
        lang_names = {
            "auto": "è‡ªåŠ¨æ£€æµ‹",
            # ä¸­æ–‡
            "zh": "ç®€ä½“ä¸­æ–‡",
            "zh-CN": "ç®€ä½“ä¸­æ–‡",
            "zh-TW": "ç¹ä½“ä¸­æ–‡",
            # è‹±æ–‡
            "en": "English",
            "en-US": "English",
            # æ—¥æ–‡
            "ja": "æ—¥æœ¬èª",
            "ja-JP": "æ—¥æœ¬èª",
            # éŸ©æ–‡
            "ko": "í•œêµ­ì–´",
            "ko-KR": "í•œêµ­ì–´",
            # æ³•æ–‡
            "fr": "FranÃ§ais",
            "fr-FR": "FranÃ§ais",
            # å¾·æ–‡
            "de": "Deutsch",
            "de-DE": "Deutsch",
            # è¥¿ç­ç‰™æ–‡
            "es": "EspaÃ±ol",
            "es-ES": "EspaÃ±ol",
            # ä¿„æ–‡
            "ru": "Ğ ÑƒÑÑĞºĞ¸Ğ¹",
            "ru-RU": "Ğ ÑƒÑÑĞºĞ¸Ğ¹",
            # é˜¿æ‹‰ä¼¯æ–‡
            "ar": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
            "ar-AR": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        }

        target_name = lang_names.get(target_language, target_language)

        # é£æ ¼æè¿°æ˜ å°„ï¼ˆæ›´ç®€æ´ï¼‰
        style_map = {
            "formal": "formal and professional",
            "casual": "casual and conversational",
            "technical": "technical and precise"
        }
        style_desc = style_map.get(style, "natural")

        # æ ¹æ®ç›®æ ‡è¯­è¨€é€‰æ‹©ç³»ç»Ÿæç¤ºè¯­è¨€ï¼ˆPhase 2 Week 4 Day 16 ä¼˜åŒ– v2ï¼‰
        # ä¸ºä¸­æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰ç›®æ ‡è¯­è¨€ä½¿ç”¨ä¸­æ–‡ç³»ç»Ÿæç¤ºï¼Œå¢å¼ºæ¨¡å‹ç†è§£
        use_chinese_prompt = target_language in ["zh", "zh-CN", "zh-TW", "ja", "ja-JP", "ko", "ko-KR"]

        if use_chinese_prompt:
            # ä¸­æ–‡ç³»ç»Ÿæç¤ºï¼ˆé’ˆå¯¹äºšæ´²è¯­è¨€ç¿»è¯‘ä¼˜åŒ–ï¼‰
            prompt = f"""ä½ æ˜¯ä¸“ä¸šç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘ä¸º{target_name}ï¼ˆ{style_desc} é£æ ¼ï¼‰ã€‚

é‡è¦è§„åˆ™ï¼š
- åªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦è§£é‡Š
- ä¸è¦é‡å¤åŸæ–‡
- ä¿ç•™åŸæ–‡çš„è¯­æ°”å’Œæ„æ€"""

            if preserve_format:
                prompt += "\n- ä¿ç•™åŸæ–‡æ ¼å¼ï¼ˆæ¢è¡Œã€æ®µè½ã€æ ‡ç‚¹ï¼‰"

            if glossary:
                glossary_str = ", ".join([f"{k}â†’{v}" for k, v in glossary.items()])
                prompt += f"\n- ä½¿ç”¨è¿™äº›æœ¯è¯­ï¼š{glossary_str}"

            # ç”¨æˆ·å†…å®¹ï¼ˆæ˜ç¡®åˆ†éš”ï¼‰
            prompt += f"\n\nåŸæ–‡ï¼š\n{text}\n\nç¿»è¯‘ç»“æœï¼š"
        else:
            # è‹±æ–‡ç³»ç»Ÿæç¤ºï¼ˆé’ˆå¯¹è¥¿æ–¹è¯­è¨€ç¿»è¯‘ï¼‰
            prompt = f"""You are a professional translator.
Translate the following text to {target_name} ({style_desc} style).

IMPORTANT:
- Only output the translation, NO explanations
- Do NOT repeat the original text
- Preserve the meaning and tone"""

            if preserve_format:
                prompt += "\n- Keep the formatting (line breaks, paragraphs, punctuation)"

            if glossary:
                glossary_str = ", ".join([f"{k}â†’{v}" for k, v in glossary.items()])
                prompt += f"\n- Use these terms: {glossary_str}"

            # ç”¨æˆ·å†…å®¹ï¼ˆæ˜ç¡®åˆ†éš”ï¼‰
            prompt += f"\n\nText to translate:\n{text}\n\nTranslation:"

        return prompt

    def _extract_translation(self, output: str) -> str:
        """ä»æ¨¡å‹è¾“å‡ºä¸­æå–ç¿»è¯‘ç»“æœ"""
        # å»é™¤å¯èƒ½çš„å‰ç¼€/åç¼€è¯´æ˜
        output = output.strip()

        # ç§»é™¤å¸¸è§çš„å‰ç¼€æ¨¡å¼
        prefixes = ["ç¿»è¯‘ç»“æœï¼š", "Translation:", "è¯‘æ–‡ï¼š", "Result:"]
        for prefix in prefixes:
            if output.startswith(prefix):
                output = output[len(prefix) :].strip()

        # ç§»é™¤ä»£ç å—æ ‡è®°ï¼ˆå¦‚æœæœ‰ï¼‰
        if output.startswith("```") and output.endswith("```"):
            lines = output.split("\n")
            output = "\n".join(lines[1:-1])

        return output.strip()
